{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Basics 2\n",
    "\n",
    "Pandas is a an open source library providing high-performance, easy-to-use data structures and data analysis tools. Pandas is particularly suited to the analysis of _tabular_ data, i.e. data that can can go into a table. In other words, if you can imagine the data in an Excel spreadsheet, then Pandas is the tool for the job.\n",
    "\n",
    "Guidance for this lesson: https://github.com/rabernat/research_computing_2018/blob/master/content/Lectures/pandas.ipynb\n",
    "\n",
    "Mad Pandas help: https://chrisalbon.com\n",
    "\n",
    "Guidance for Git: http://swcarpentry.github.io/git-novice/\n",
    "\n",
    "Documentation for visualizations: https://hvplot.pyviz.org/user_guide/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Math on Arrays\n",
    "\n",
    "The goal of these next few questions are for you to demonstrate the ability to do basic math on arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4. Add a cell and use it to create a matrix:\n",
    "\n",
    "matrix = np.array([[1,2,3],\n",
    "                 [4,5,6],\n",
    "                 [7,8,9]])\n",
    "\n",
    "#What command would you use to calculate the mean of this array using numpy? \n",
    "\n",
    "np.mean(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Data Structures: Series\n",
    "\n",
    "A Series represents a one-dimensional array of data. The main difference between a Series and numpy array is that a Series has an index. The index contains the labels that we use to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7.\n",
    "#1. Add a code cell below that creates the following series:\n",
    "\n",
    "names = (['Aida','Josh','Jordan'])\n",
    "values = ([36,37,2.7])\n",
    "ages = pd.Series(values,index = names)\n",
    "ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. In the next cell create a bar graph from the series:\n",
    "\n",
    "ages.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Data Structures: DataFrame\n",
    "\n",
    "There is a lot more to Series, but they are limit to a single \"column\". A more useful Pandas data structure is the DataFrame. A DataFrame is basically a bunch of series that share the same index. It's a lot like a table in a spreadsheet.\n",
    "Below we create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 8. First we create a dictionary:\n",
    "\n",
    "data = {'age':[36,37,1.7],\n",
    "       'height':[180,155,90],\n",
    "       'weight':[78,np.nan,11.3]}\n",
    "df = pd.DataFrame(data,index = ['Ryan','Chiara','Johnny'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 9. If we make a calculation using columns from the DataFrame, it will keep the same index:\n",
    "\n",
    "df['density'] = df.weight/df.height\n",
    "df\n",
    "\n",
    "#What is Ryan's calculated density to three decimal places?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 10. Create a new index using a boolean series:\n",
    "\n",
    "df['is_adult'] = df.age > 18\n",
    "df\n",
    "\n",
    "#Which of our participants returns a \"False\" in our new DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying Values: \n",
    "\n",
    "We often want to modify values in a dataframe based on some rule. To modify values, we need to use .loc or .iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 11. #Here is an example: \n",
    "\n",
    "df.loc['Johnny','height'] = 95\n",
    "df.loc['Ryan','weight'] += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we use the iloc command, what syntax would allow us to similarly change our entry for Johnny's height?\n",
    "\n",
    "df.iloc[2,1] = 100\n",
    "\n",
    "#If we use the iloc command, what could would allow us to similarly add 1 to Ryan's weight? \n",
    "\n",
    "df.iloc[0,2] += 1\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "DataFrames have all kinds of useful plotting built in.  Review the plotting documentation for hvplot (https://hvplot.pyviz.org/user_guide/Introduction.html) and then plot some data from our data frame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 12. Add a new code box and build your first plot:\n",
    "\n",
    "df.hvplot(x = 'age',y = 'height', \n",
    "          kind = 'scatter', grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How does it look? \n",
    "#I think in this case it might be helpful to specify the limits on our x and y axis.\n",
    "#Let's modify our code by adding those limits:\n",
    "\n",
    "df.hvplot(x = 'age',y = 'height', \n",
    "          kind = 'scatter', grid = True,\n",
    "         xlim = (0,40), ylim = (0,200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 13. Now read the documentation for hvplot and add the variable 'weight' to your plot. \n",
    "\n",
    "df.hvplot(x = 'age',y = ['height','weight'],\n",
    "          kind = 'scatter', grid = True,\n",
    "         xlim = (0,40), ylim = (0,200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 14. Read the hvplot documentation and create this bar graph and upload your results:\n",
    "\n",
    "df.hvplot(x = 'index',y = ['age','height','is_adult','weight'], c = ['blue','darkorange','red','green'],\n",
    "          kind = 'bar', grid = False,\n",
    "         xlim = (0,40), ylim = (0,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Indexes\n",
    "\n",
    "Indexes are very powerful. They are a big part of why Pandas is so useful. There are different indices for different types of data. Time Indexes are especially great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 15. Add a cell and create two years of time series data: \n",
    "\n",
    "two_years = pd.date_range(start = '2014-01-01', end = '2016-01-01',freq = 'D')\n",
    "timeseries = pd.Series(np.sin(2*np.pi*two_years.dayofyear/365), index = two_years)\n",
    "timeseries.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Data Files: Weather Station Data\n",
    "\n",
    "In this example, we will use NOAA weather station data from https://www.ncdc.noaa.gov/data-access/land-based-station-data.\n",
    "The details of files we are going to read are described in this README file: ftp://ftp.ncdc.noaa.gov/pub/data/uscrn/products/daily01/README.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget ftp://ftp.ncdc.noaa.gov/pub/data/uscrn/products/daily01/HEADERS.txt\n",
    "!wget ftp://ftp.ncdc.noaa.gov/pub/data/uscrn/products/daily01/2017/CRND0103-2017-NY_Millbrook_3_W.txt\n",
    "!head -2 HEADERS.txt | tail -1 > data.txt\n",
    "!cat CRND0103-2017-NY_Millbrook_3_W.txt >> data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a text file on our hard drive called `data.txt`. Examine it.\n",
    "\n",
    "To read it into pandas, we will use the 'read_csv' (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) function. This function is incredibly complex and powerful. You can use it to extract data from almost any text file. However, you need to understand how to use its various options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 17. With no options, it looks like this:\n",
    "\n",
    "df = pd.read_csv('data.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you execute this command you will see a dataframe that is not very useful? What happened?  \n",
    "\n",
    "Pandas failed to identify the different columns. This is because it was expecting standard CSV (comma-separated values) file. In our file, instead, the values are separated by whitespace. And not a single whilespace--the amount of whitespace between values varies. We can tell pandas this using the `sep` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In a new cell add:\n",
    "\n",
    "df = pd.read_csv('CRND0103-2017-NY_Millbrook_3_W.txt', sep = '\\s+')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it worked, you should see something much more useful in your workspace. When you look closely, you will see there are lots of -99 and -9999 values in the file. The [README file](ftp://ftp.ncdc.noaa.gov/pub/data/uscrn/products/daily01/README.txt) tells us that these are values used to represent missing data. Let's tell this to pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In a new cell add:\n",
    "\n",
    "df = pd.read_csv('data.txt', sep = '\\s+')\n",
    "na_values = [-9999.0,-99]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now missing data is now represented by a NaN. Let's investigate what data types pandas inferred. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In a new cell add:\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem here is that pandas did not recognize the `LDT_DATE` column as a date. Let's help it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.txt', sep = '\\s+',\n",
    "                na_values = [-9999.0, -99],\n",
    "                parse_dates = [1])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should work! Finally, let's tell pandas to use the date column as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('LST_DATE')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can access these values by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['2017-08-07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 18: What code does it take to use .loc to select a subset of the dataframe that ranges from 2017-07-01 to 2017-07-31? \n",
    "\n",
    "df.loc['2017-07-01':'2017-07-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 19. Add a cell and use the .describe feature to do some quick statistics.\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 20. Now let's look at how well Pandas and hvplot deals with time. Add a cell:\n",
    "\n",
    "df.T_DAILY_MEAN.hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets add a custom title:\n",
    "\n",
    "df.T_DAILY_MEAN.hvplot(title='hvplot made this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets pull in some more data: \n",
    "\n",
    "df[['T_DAILY_MIN','T_DAILY_MEAN','T_DAILY_MAX']].hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is helpful... but sometimes it is useful to plot related data sets separately and retain the ability to closely examine how the variables are related to each other. Hvplot has a wonderful ability to link axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hvplot.scatter(x = 'LST_DATE', y = [])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
