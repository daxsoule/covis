{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical tests:\n",
    "* The goal here is to use statistical tests to identify or confirm correlations and common patterns.  Correlation tests include the correlation coefficient (sometimes known as R2) and cross-correlation. Correlation coefficients test if variables shift value in sync.  Cross-correlation compares pairs of time series and tests for consistent long-term patterns.  We will also look for periodicities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits import mplot3d\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews import dim, opts\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "def inc(x):\n",
    "    sleep(1)\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    sleep(1)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def dateparse (date_string):\n",
    "    return datetime.datetime.strptime(date_string, '%d-%m-%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step One - Gather Data\n",
    "\n",
    "Plume Bending Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test path to data using unix command \n",
    "#!ls /home/jovyan/data/covis_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notes:\n",
    "1. For direction, units are degrees. Both 0 degrees and 360 degrees are North.  Probably Magnetic North rather than True North.\n",
    "2. Angle from vertical is also in degrees.\n",
    "3. The time is in a modified Julian Day format. Modified in that it is only days since January of the appropriate year AND that it likely starts at midnight not noon.\n",
    "4. The BendData are a linear fit to a centerline of an isosurface  representing a plume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'covis/diaz/Covis_Data/angles_partialpts_2010.dat' # use your path\n",
    "df_bd2010 = pd.read_csv(path, sep=\",\")\n",
    "df_bd2010['year'] = '2010'\n",
    "df_bd2010['datetime'] = pd.to_datetime(df_bd2010.year, format='%Y') + pd.to_timedelta(df_bd2010.jday - 1, unit='d')\n",
    "df_bd2010['datetime'] = df_bd2010['datetime'].dt.round('1s')\n",
    "df_bd2010 = df_bd2010.set_index('datetime')\n",
    "df_bd2010.drop(['jday', 'year'], axis=1,inplace=True)\n",
    "df_bd2010 = df_bd2010.rename_axis(None)\n",
    "df_bd2010 = df_bd2010.resample('h').mean()\n",
    "df_bd2010.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_bd2010.hvplot(x = 'index', y= ['direction'], kind = 'scatter') * df_bd2010.hvplot(x = 'index', y= ['direction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_bd2010.hvplot(x = 'index', y= ['direction', 'deg_from_vert'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather data\n",
    "* I'm not sure how useful this file will be or what timeframe it covers.  An explanation of the variable names can be found at https://www.ndbc.noaa.gov/measdes.shtml\n",
    "* weather_data_for_plotting*.txt files\n",
    "* 13 variables (Year, Month, Day, Hour, Minute, Seconds, Julian day, wave height, wind direction, wind speed, wind gust speed, atmospheric pressure, air temperature)\n",
    "* separator = single blank space\n",
    "### notes:\n",
    "1. Time is given both as a vector (from original data file probably) and as a Julian day.\n",
    "2. No information on other units by m/s likely for speeds.  Rest should match the NOAA information.  \n",
    "3. I probably still have the original NOAA data files for these buoys. I'll see if I can match data files to the time periods; my directories seemed a little confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/jovyan/data/covis_data/weather_data_for_plotting_2010_C46036.csv' # use your path\n",
    "df_wd2010c46036 = pd.read_csv(path, sep=\",\")\n",
    "df_wd2010c46036['year']= df_wd2010c46036['year'].astype(int).astype(str)\n",
    "df_wd2010c46036['month']= df_wd2010c46036['month'].astype(int).astype(str).str.pad(width=2, side='left', fillchar='0')\n",
    "df_wd2010c46036['day']= df_wd2010c46036['day'].astype(int).astype(str).str.pad(width=2, side='left', fillchar='0')\n",
    "df_wd2010c46036['hour']= df_wd2010c46036['hour'].astype(int).astype(str).str.pad(width=2, side='left', fillchar='0')\n",
    "df_wd2010c46036['minute']=df_wd2010c46036['minute'].astype(int).astype(str).str.pad(width=2, side='left', fillchar='0')\n",
    "df_wd2010c46036['datetime'] = df_wd2010c46036['year'] + df_wd2010c46036['month'] + df_wd2010c46036['day'] +\\\n",
    "'T' + df_wd2010c46036['hour']+ ':' + df_wd2010c46036['minute']\n",
    "df_wd2010c46036['datetime'] = pd.to_datetime(df_wd2010c46036['datetime'])\n",
    "df_wd2010c46036 = df_wd2010c46036.set_index('datetime')\n",
    "df_wd2010c46036 = df_wd2010c46036[['jday', 'wv_height', 'wnd_dir', 'wnd_spd', 'wnd_gspd', 'atm_prs', 'air_temp']]\n",
    "df_wd2010c46036 = df_wd2010c46036.rename_axis(None)\n",
    "df_wd2010c46036 = df_wd2010c46036.resample('h').mean()\n",
    "df_wd2010c46036.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(df_wd2010c46036, df_bd2010,how='inner', indicator=True, left_index=True, right_index=True, suffixes=('_B', '_G'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covis = pd.DataFrame()\n",
    "df_covis = test[test['_merge'] == 'both']\n",
    "del df_covis['_merge']\n",
    "df_covis = df_covis.dropna()\n",
    "df_covis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covis.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/jovyan/data/covis_data/recomputed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take quick look at data using unix command \n",
    "!echo 'date,inclination,azimuth' | cat - ~jovyan/data/covis_data/recomputed/angles_partialpts_2010.dat > ~jovyan/data/covis_data/temp.txt\n",
    "!sed 's/ /,/g' ~jovyan/data/covis_data/temp.txt > ~jovyan/data/covis_data/recomputed/angles_partialpts_2010.csv\n",
    "!head /home/jovyan/data/covis_data/recomputed/angles_partialpts_2010.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/jovyan/data/covis_data/recomputed/angles_partialpts_2010.csv' # use your path\n",
    "df_rc2010 = pd.read_csv(path, sep=\",\")\n",
    "df_rc2010['year'] = '2010'\n",
    "df_rc2010['datetime'] = pd.to_datetime(df_rc2010.year, format='%Y') + pd.to_timedelta(df_rc2010.date - 1, unit='d')\n",
    "df_rc2010['datetime'] = df_rc2010['datetime'].dt.round('1s')\n",
    "df_rc2010 = df_rc2010.set_index('datetime')\n",
    "df_rc2010.drop(['date', 'year'], axis=1,inplace=True)\n",
    "df_rc2010 = df_rc2010.rename_axis(None)\n",
    "df_rc2010 = df_rc2010.resample('h').mean()\n",
    "df_rc2010.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(df_wd2010c46036, df_rc2010,how='inner', indicator=True, left_index=True, right_index=True, suffixes=('_B', '_G'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covis_rc = pd.DataFrame()\n",
    "df_covis_rc = test[test['_merge'] == 'both']\n",
    "del df_covis_rc['_merge']\n",
    "df_covis_rc = df_covis_rc.dropna()\n",
    "del df_covis_rc['jday']\n",
    "df_covis_rc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = df_covis_rc.hvplot.scatter(y='wnd_dir', color='wnd_spd',\n",
    "                                     cmap='colorwheel', s= 'wnd_spd',\n",
    "                                     scale = 2, height=200,\n",
    "                                     title= 'Example Plots',\n",
    "                                     ylabel= 'Wind Direction (deg)',\n",
    "                                     ylim = (0, 400),hover_cols=['wv_height'])\n",
    "bending = df_covis_rc.hvplot.scatter(y='azimuth',color='inclination',\n",
    "                                     cmap='viridis', s= 'wnd_spd',\n",
    "                                     scale = 2, height=200,\n",
    "                                     ylabel= 'Azimuth (deg)',\n",
    "                                     xlabel = 'Time (h)',\n",
    "                                     ylim = (-160, 150)).hist() \n",
    "(weather + bending).cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above we have two figures that allow for comparison over time of the various parameters we are interested. The top figure uses the y axis to plot wind direction, and uses both color and dot size to communicate wind speed. \n",
    "\n",
    "### The second plot uses the y axis to plot azimuth and uses color to communicate inclination... the wind speed is still communicated using size.\n",
    "\n",
    "## Issues:\n",
    "1. Both correlation coefficient estimation and cross-correlation computation assume that the values in the different datasets correspond â€¦ here it would be in time.  So we will need to do some interpolation to get our time series onto similar sampling times.\n",
    "2. Most estimators of periodicity assume regular or uniform spacing of the data. There are, however, methods for working with data with gaps.\n",
    "3. Periodicity estimates also change with the length of the data set.  So we will need to think about how to best compare the 2010 and 2011 data sets given the short 2010 record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covis_rc.hvplot.scatter(x = 'wnd_dir', y= 'azimuth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covis_rc.hvplot.scatter(x = 'wnd_spd', y= 'inclination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covis_rc.wnd_spd.hvplot.violin(by='index.day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A game plan for step 3:\n",
    "1. Extract timing information for the various data sets, especially start time, stop time, and time intervals.  We need both the typical (not necessarily average) time step as well as some information on the number and size of data gaps.  We will use this to determine how to proceed with the correlation steps.  In particular, it will be useful to know which data are sampled at similar or faster rates than the plume bending data.\n",
    "2. Estimate some basic statistics for key data sets: means, standard deviations, obvious trends.  This will be useful in defining what extreme bending means if nothing else.\n",
    "3. Identify which data sets are key. Which data sets are central to the goals or questions?  Which data sets seem to have common features, patterns, or trends?  This may require plotting data together in ways or combinations that have not yet seemed obvious.\n",
    "4. Interpolate data onto a common time sampling scheme.  All the COVIS data should be at similar but not necessarily identical times: the vertical velocity data will be offset about 20-40 minutes later than the bending data and may have more gaps.  I don't remember about the weather data and each buoy may be different.  I forget what else there is that I gave you.  I think there is some relevant data that we have not yet pulled from its repository.\n",
    "\n",
    "So you might think a little about what information you'd like to have but don't.\n",
    "Once interpolated to a common sampling, you can estimate the correlation coefficient.  This expects a linear pattern so it might or might not pick up on all relationships that exist.  Also, some of the directions in the bending data are not correct.  So I need to get you an updated data file soon. But you can figure out how  to do this with the existing data while I figure out the problems with the old data.\n",
    "Cross-correlation is the next step after that.\n",
    "Then we need to figure out about periodicities.  The Lomb-Scargle method is the best one for this data.  I think it exists in python but we will need to track that information down.\n",
    "Another things to think about is the definition of a weather event.  What is a storm? How will it appear in the data? What does that mean about what we expect to find in the bending data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a bending event? \n",
    "What is a storm? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
